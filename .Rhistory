table(new_train$HeartDiseaseorAttack, health_lda$class)
123682+133503
257185/334004
33499+133503
133503/167002
# 10 fold CV
health_lda_xval <- rep(0, length = nrow(new_train))
x <- rep(1:10, length = nrow(new_train))
x <- sample(x)
for(i in 1:10){
xtrain <- new_train[x != i, ]
xtest <- new_train[x == i, ]
glub <- lda(HeartDiseaseorAttack ~ . , data = xtrain)
health_lda_xval[x == i] <- predict(glub, xtest)$class
}
table(new_train$HeartDiseaseorAttack, health_lda_xval)
123695+133457
257152/334004
33545+133457
133457/167002
# Test Set Prediction
table(new_test$HeartDiseaseorAttack, predict(health_lda, new_test)$class)
# Test Set Prediction
lda_pred <- predict(health_lda, new_test)
class.sum(new_test$HeartDiseaseorAttack, predict(health_lda, new_test)$posterior[,2])
health_qda <- qda(HeartDiseaseorAttack ~ . , CV = TRUE, data = new_train)
# LOO CV Confusion Matrix
table(new_train$HeartDiseaseorAttack, health_qda$class)
96997+147354
244351/334004
19648+147354
147354/167002
# 10 fold CV
health_qda_xval_class <- rep(0, nrow(new_train))
health_qda_xval_posterior <- rep(0, nrow(new_train))
xvs <- rep(1:10, length = nrow(new_train))
xvs <- sample(xvs)
for(i in 1:10){
xtrain <- new_train[xvs != i, ]
xtest <- new_train[xvs == i, ]
glub <- qda(HeartDiseaseorAttack ~ . , data = xtrain)
health_qda_xval_posterior[xvs == i] <- predict(glub, xtest)$posterior[, 2]
health_qda_xval_class[xvs == i] <- predict(glub, xtest)$class
}
table(new_train$HeartDiseaseorAttack, health_qda_xval_class)
96958+147379
244337/334004
19623+147379
147379/167002
rf_best_features <- new_train %>% dplyr::select(HeartDiseaseorAttack, Age, GenHlth, ln.BMI, Income, HighBP, Education, HighChol)
lasso_best_features <- new_train %>% dplyr::select(HeartDiseaseorAttack, HighBP,
HighChol, CholCheck, Smoker,
Stroke, Diabetes, HvyAlcoholConsump,
NoDocbcCost, GenHlth, DiffWalk,
Sex, Age, Income, bin.PhysHlth)
lasso_test_features <- new_test %>% dplyr::select(HeartDiseaseorAttack, HighBP,
HighChol, CholCheck, Smoker,
Stroke, Diabetes, HvyAlcoholConsump,
NoDocbcCost, GenHlth, DiffWalk,
Sex, Age, Income, bin.PhysHlth)
rf_test_features <- new_test %>% dplyr::select(HeartDiseaseorAttack, Age, GenHlth, ln.BMI, Income, HighBP, Education, HighChol)
# Using RF variables
health_lda_rf <- lda(HeartDiseaseorAttack ~ . , CV = TRUE, data = rf_best_features)
# LOO CV Confusion Matrix
table(rf_best_features$HeartDiseaseorAttack, health_lda$class)
123682+133503
257185/334004
33499+133503
133503/167002
# 10 fold CV
health_lda_xval <- rep(0, length = nrow(rf_best_features))
x <- rep(1:10, length = nrow(rf_best_features))
x <- sample(x)
for(i in 1:10){
xtrain <- new_train[x != i, ]
xtest <- new_train[x == i, ]
glub <- lda(HeartDiseaseorAttack ~ . , data = xtrain)
health_lda_xval[x == i] <- predict(glub, xtest)$class
}
# 10 fold CV
health_lda_xval <- rep(0, length = nrow(rf_best_features))
x <- rep(1:10, length = nrow(rf_best_features))
# 10 fold CV
health_lda_xval <- rep(0, length = nrow(rf_best_features))
# LOO CV Confusion Matrix
table(rf_best_features$HeartDiseaseorAttack, health_lda$class)
table(new_train$HeartDiseaseorAttack, health_lda_xval)
knitr::opts_chunk$set(echo = FALSE)
library(ada)
library(gbm)
library(caret)
library(e1071)
library(EZtune)
library(caTools)
library(tidyverse)
source('kappa_and_class_sum.R')
library(randomForest)
library(glmnet)
health <- read.csv("heart_disease_health_indicators.csv")
health <- health %>% mutate(
HeartDiseaseorAttack = HeartDiseaseorAttack,
HighBP = as.factor(HighBP),  # LASSO approved
HighChol = as.factor(HighChol),  # LASSO approved
CholCheck = as.factor(CholCheck),
ln.BMI = log(BMI),  # RF approved
Smoker = as.factor(Smoker),  # LASSO approved
Stroke = as.factor(Stroke),  # LASSO 1-SE only, RF approved
Diabetes = as.factor(Diabetes),  # LASSO approved, RF approved
PhysActivity = as.factor(PhysActivity),
Fruits = as.factor(Fruits),
Veggies = as.factor(Veggies),
HvyAlcoholConsump = as.factor(HvyAlcoholConsump),
AnyHealthcare = as.factor(AnyHealthcare),
NoDocbcCost = as.factor(NoDocbcCost),  # LASSO approved
GenHlth = as.factor(GenHlth),  # LASSO approved, RF approved
ln.MentHlth = log(MentHlth + 1), # Probably shouldn't use
bin.MentHlth = as.factor(ifelse(MentHlth == 0, 0, 1)),  #RF approved
fac.MentHlth = as.factor(MentHlth), # Probably shouldn't use
ln.PhysHlth = log(PhysHlth + 1), # Probably shouldn't use
bin.PhysHlth = as.factor(ifelse(PhysHlth == 0, 0, 1)),  # LASSO approved, RF approved
fac.PhysHlth = as.factor(PhysHlth), # Probably shouldn't use
DiffWalk = as.factor(DiffWalk),  # LASSO , RF approved
Sex = as.factor(ifelse(Sex == 0, "F", "M")),  # LASSO approved, RF approved
Age = as.factor(Age),  # LASSO approved, RF approved
Education = as.factor(Education),  # RF approved
Income = as.factor(Income)  # LASSO approved, RF approved
)
# new data with transformed variables
health_subset <- health[c(1:4, 6:15, 18:23, 25, 28)]
# Train and Test Sets
health_tmp <- sample.split(health_subset, SplitRatio = 0.3)
test <- subset(health_subset, health_tmp == TRUE)
train <- subset(health_subset, health_tmp == FALSE)
## Randomly sample rows
train_sample <- sample_n(train, 5000)
## UpSample to deal with class imbalance
new_train <- upSample(train[,2:22], as.factor(train[,1]), list=FALSE)
new_train$HeartDiseaseorAttack <- new_train$Class
new_train <- new_train[,-22]
## Test Set Upsample ##
new_test <- upSample(test[,2:22], as.factor(test[,1]), list = FALSE)
new_test$HeartDiseaseorAttack <- new_test$Class
new_test <- new_test[,-22]
rf_best_features <- new_train %>% dplyr::select(HeartDiseaseorAttack, Age, GenHlth, ln.BMI, Income, HighBP, Education, HighChol)
rf_test_features <- new_test %>% dplyr::select(HeartDiseaseorAttack, Age, GenHlth, ln.BMI, Income, HighBP, Education, HighChol)
lasso_best_features <- new_train %>% dplyr::select(HeartDiseaseorAttack, HighBP,
HighChol, CholCheck, Smoker,
Stroke, Diabetes, HvyAlcoholConsump,
NoDocbcCost, GenHlth, DiffWalk,
Sex, Age, Income, bin.PhysHlth)
lasso_test_features <- new_test %>% dplyr::select(HeartDiseaseorAttack, HighBP,
HighChol, CholCheck, Smoker,
Stroke, Diabetes, HvyAlcoholConsump,
NoDocbcCost, GenHlth, DiffWalk,
Sex, Age, Income, bin.PhysHlth)
# Using RF variables
health_lda_rf <- lda(HeartDiseaseorAttack ~ . , CV = TRUE, data = rf_best_features)
# LOO CV Confusion Matrix
table(rf_best_features$HeartDiseaseorAttack, health_lda$class)
# LOO CV Confusion Matrix
table(rf_best_features$HeartDiseaseorAttack, health_lda_rf$class)
119320+133208
252528/334296
34940+132208
132208/167148
# 10 fold CV
health_lda_xval <- rep(0, length = nrow(rf_best_features))
x <- rep(1:10, length = nrow(rf_best_features))
x <- sample(x)
for(i in 1:10){
xtrain <- rf_best_features[x != i, ]
xtest <- rf_best_features[x == i, ]
glub <- lda(HeartDiseaseorAttack ~ . , data = xtrain)
health_lda_xval[x == i] <- predict(glub, xtest)$class
}
table(rf_best_features$HeartDiseaseorAttack, health_lda_xval)
119325+132169
251494/334296
34979+132169
132169/167148
# Using LASSO variables
health_lda_lasso <- lda(HeartDiseaseorAttack ~ . , CV = TRUE, data = lasso_best_features)
# LOO CV Confusion Matrix
table(lasso_best_features$HeartDiseaseorAttack, health_lda_lasso$class)
123930+133713
257643/334296
33435+133713
133713/167148
# 10 fold CV
health_lda_xval <- rep(0, length = nrow(lasso_best_features))
x <- rep(1:10, length = nrow(lasso_best_features))
x <- sample(x)
for(i in 1:10){
xtrain <- lasso_best_features[x != i, ]
xtest <- lasso_best_features[x == i, ]
glub <- lda(HeartDiseaseorAttack ~ . , data = xtrain)
health_lda_xval[x == i] <- predict(glub, xtest)$class
}
table(lasso_best_features$HeartDiseaseorAttack, health_lda_xval)
123972+133748
257720/334296
33400+133748
133748/167148
# Using RF variables
health_qda_rf <- qda(HeartDiseaseorAttack ~ . , CV = TRUE, data = rf_best_features)
# LOO CV Confusion Matrix
table(rf_best_features$HeartDiseaseorAttack, health_qda$class)
# LOO CV Confusion Matrix
table(rf_best_features$HeartDiseaseorAttack, health_qda_rf$class)
88255+150396
238651/334296
150396+16752
150396/1671478
150396/167148
# 10 fold CV
health_qda_xval_class <- rep(0, nrow(rf_best_features))
health_qda_xval_posterior <- rep(0, nrow(rf_best_features))
xvs <- rep(1:10, length = nrow(new_train))
xvs <- sample(xvs)
for(i in 1:10){
xtrain <- rf_best_features[xvs != i, ]
xtest <- rf_best_features[xvs == i, ]
glub <- qda(HeartDiseaseorAttack ~ . , data = xtrain)
health_qda_xval_posterior[xvs == i] <- predict(glub, xtest)$posterior[, 2]
health_qda_xval_class[xvs == i] <- predict(glub, xtest)$class
}
table(rf_best_features$HeartDiseaseorAttack, health_qda_xval_class)
88282+150412
238694/334296
150412+16736
150412/167148
# Using LASSO variables
health_qda_lasso <- qda(HeartDiseaseorAttack ~ . , CV = TRUE, data = lasso_best_features)
# LOO CV Confusion Matrix
table(lasso_best_features$HeartDiseaseorAttack, health_qda_lasso$class)
91209+149996
241205/334296
17152+149996
149996/167148
# 10 fold CV
health_qda_xval_class <- rep(0, nrow(lasso_best_features))
health_qda_xval_posterior <- rep(0, nrow(lasso_best_features))
xvs <- rep(1:10, length = nrow(lasso_best_features))
xvs <- sample(xvs)
for(i in 1:10){
xtrain <- lasso_best_features[xvs != i, ]
xtest <- lasso_best_features[xvs == i, ]
glub <- qda(HeartDiseaseorAttack ~ . , data = xtrain)
health_qda_xval_posterior[xvs == i] <- predict(glub, xtest)$posterior[, 2]
health_qda_xval_class[xvs == i] <- predict(glub, xtest)$class
}
table(lasso_best_features$HeartDiseaseorAttack, health_qda_xval_class)
91178+150040
241218/334296
17108+150040
150040/167148
library(ada)
library(gbm)
library(caret)
library(e1071)
library(EZtune)
library(caTools)
library(tidyverse)
source('kappa_and_class_sum.R')
library(randomForest)
library(glmnet)
health <- read.csv("heart_disease_health_indicators.csv")
health <- health %>% mutate(
HeartDiseaseorAttack = HeartDiseaseorAttack,
HighBP = as.factor(HighBP),  # LASSO approved
HighChol = as.factor(HighChol),  # LASSO approved
CholCheck = as.factor(CholCheck),
ln.BMI = log(BMI),  # RF approved
Smoker = as.factor(Smoker),  # LASSO approved
Stroke = as.factor(Stroke),  # LASSO 1-SE only, RF approved
Diabetes = as.factor(Diabetes),  # LASSO approved, RF approved
PhysActivity = as.factor(PhysActivity),
Fruits = as.factor(Fruits),
Veggies = as.factor(Veggies),
HvyAlcoholConsump = as.factor(HvyAlcoholConsump),
AnyHealthcare = as.factor(AnyHealthcare),
NoDocbcCost = as.factor(NoDocbcCost),  # LASSO approved
GenHlth = as.factor(GenHlth),  # LASSO approved, RF approved
ln.MentHlth = log(MentHlth + 1), # Probably shouldn't use
bin.MentHlth = as.factor(ifelse(MentHlth == 0, 0, 1)),  #RF approved
fac.MentHlth = as.factor(MentHlth), # Probably shouldn't use
ln.PhysHlth = log(PhysHlth + 1), # Probably shouldn't use
bin.PhysHlth = as.factor(ifelse(PhysHlth == 0, 0, 1)),  # LASSO approved, RF approved
fac.PhysHlth = as.factor(PhysHlth), # Probably shouldn't use
DiffWalk = as.factor(DiffWalk),  # LASSO , RF approved
Sex = as.factor(ifelse(Sex == 0, "F", "M")),  # LASSO approved, RF approved
Age = as.factor(Age),  # LASSO approved, RF approved
Education = as.factor(Education),  # RF approved
Income = as.factor(Income)  # LASSO approved, RF approved
)
# new data with transformed variables
health_subset <- health[c(1:4, 6:15, 18:23, 25, 28)]
# Train and Test Sets
health_tmp <- sample.split(health_subset, SplitRatio = 0.3)
test <- subset(health_subset, health_tmp == TRUE)
train <- subset(health_subset, health_tmp == FALSE)
## Randomly sample rows
train_sample <- sample_n(train, 5000)
## UpSample to deal with class imbalance
new_train <- upSample(train[,2:22], as.factor(train[,1]), list=FALSE)
head(new_train)
str(new_train)
## UpSample to deal with class imbalance
new_train <- upSample(train[,2:22], as.factor(train[,1]), list=FALSE) %>%
mutate(HeartDiseaseorAttack = as.numeric(Class))
str(new_train)
## Test Set Upsample ##
new_test <- upSample(test[,2:22], as.factor(test[,1]), list = FALSE) %>%
mutate(HeartDiseaseorAttack = as.numeric(Class))
rf_best_features <- new_train %>% dplyr::select(HeartDiseaseorAttack, Age, GenHlth, ln.BMI, Income, HighBP, Education, HighChol)
rf_test_features <- new_test %>% dplyr::select(HeartDiseaseorAttack, Age, GenHlth, ln.BMI, Income, HighBP, Education, HighChol)
train_sample <- sample_n(rf_best_features, 10000)
test_sample <- sample_n(rf_test_features, 10000)
str(train_sample)
rf_best_features <- new_train %>% dplyr::select(HeartDiseaseorAttack, Age, GenHlth, ln.BMI, Income, HighBP, Education, HighChol)
rf_test_features <- new_test %>% dplyr::select(HeartDiseaseorAttack, Age, GenHlth, ln.BMI, Income, HighBP, Education, HighChol)
str(rf_best_features)
train_sample <- sample_n(rf_best_features, 10000)
test_sample <- sample_n(rf_test_features, 10000)
str(train_sample)
rf <- randomForest(as.factor(HeartDiseaseorAttack) ~ ., data = train_sample, n.trees = 100, importance = TRUE)
class.sum(as.numeric(train_sample$HeartDiseaseorAttack), predict(rf, type="prob")[,2], cap = "Training Data RF Performance")
typeof(train_sample$HeartDiseaseorAttack)
is.numeric(train_sample$HeartDiseaseorAttack)
summary(train_sample$HeartDiseaseorAttack)
is.na(train_sample$HeartDiseaseorAttack)
predict(rf, type="prob")[,2]
summary(predict(rf, type="prob")[,2])
rf$confusion
predict(rf, type="prob")[,1]
class.sum(train_sample$HeartDiseaseorAttack, predict(rf, type="prob")[,2], cap = "Training Data RF Performance")
class.sum(test_sample$HeartDiseaseorAttack, predict(rf, test_sample, type="prob")[,2], cap = "Test Data RF Performance")
table(train_sample$HeartDiseaseorAttack,predict(rf,type="class"))
rf$confusion
typeof(predict(rf, type="prob")[,2])
typeof(train_sample$HeartDiseaseorAttack)
class.sum(train_sample$HeartDiseaseorAttack, predict(rf, type="prob")[,2], cap = "Training Data RF Performance")
?roc.area
summarise(test_sample$HeartDiseaseorAttack)
View(train_sample$HeartDiseaseorAttack)
View(train_sample)
sum(is.na(train_sample$HeartDiseaseorAttack))
View(test_sample)
## UpSample to deal with class imbalance
new_train <- upSample(train[,2:22], as.factor(train[,1]), list=FALSE) %>%
mutate(HeartDiseaseorAttack = as.numeric(Class)-1)
## Test Set Upsample ##
new_test <- upSample(test[,2:22], as.factor(test[,1]), list = FALSE) %>%
mutate(HeartDiseaseorAttack = as.numeric(Class)-1)
## UpSample to deal with class imbalance
new_train <- upSample(train[,2:22], as.factor(train[,1]), list=FALSE) %>%
mutate(HeartDiseaseorAttack = as.numeric(Class)-1)
## Test Set Upsample ##
new_test <- upSample(test[,2:22], as.factor(test[,1]), list = FALSE) %>%
mutate(HeartDiseaseorAttack = as.numeric(Class)-1)
rf_best_features <- new_train %>% dplyr::select(HeartDiseaseorAttack, Age, GenHlth, ln.BMI, Income, HighBP, Education, HighChol)
rf_test_features <- new_test %>% dplyr::select(HeartDiseaseorAttack, Age, GenHlth, ln.BMI, Income, HighBP, Education, HighChol)
train_sample <- sample_n(rf_best_features, 10000)
test_sample <- sample_n(rf_test_features, 10000)
View(train_sample)
rf <- randomForest(as.factor(HeartDiseaseorAttack) ~ ., data = train_sample, n.trees = 100, importance = TRUE)
rf$confusion
class.sum(train_sample$HeartDiseaseorAttack, predict(rf, type="prob")[,2], cap = "Training Data RF Performance")
class.sum(test_sample$HeartDiseaseorAttack, predict(rf, test_sample, type="prob")[,2], cap = "Test Data RF Performance")
class.sum(train_sample$HeartDiseaseorAttack, predict(rf, type="prob")[,2], cap = "Training Data RF Performance")
class.sum(test_sample$HeartDiseaseorAttack, predict(rf, test_sample, type="prob")[,2], cap = "Test Data RF Performance")
class.sum(train_sample$HeartDiseaseorAttack, predict(rf, type="prob")[,2], cap = "Training Data RF Performance")
set.seed(89729)
rf <- randomForest(as.factor(HeartDiseaseorAttack) ~ ., data = train_sample, n.trees = 100, importance = TRUE)
class.sum(train_sample$HeartDiseaseorAttack, predict(rf, type="prob")[,2], cap = "Training Data RF Performance")
class.sum(test_sample$HeartDiseaseorAttack, predict(rf, test_sample, type="prob")[,2], cap = "Test Data RF Performance")
systemctl status rstudio-launcher
knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
results <- data.frame(PCC = c(76.99, 75.23, 77.09, 73.15, 71.40, 72.16, 77.10),
Specificity = c(79.91, 79.07, 80.01, 88.25, 89.99, 89.76,
79.53))
rownames(results) <- c("LDA", "LDA w/RF-Selected Variables",
"LDA w/LASSO-Selected Variables", "QDA", "QDA w/RF-Selected Variables",
"QDA w/LASSO-Selected Variables", "LASSO Logistic Regression")
results %>%
kbl(caption = "Prediction Results for Individual Methods") %>%
kable_classic(full_width = FALSE, html_font = "Cambria",
latex_options = "HOLD_position")
results <- data.frame(PCC = c(76.99, 75.23, 77.09, 73.15, 71.40, 72.16, 77.10),
Specificity = c(79.91, 79.07, 80.01, 88.25, 89.99, 89.76,
79.53))
rownames(results) <- c("LDA", "LDA w/RF-Selected Variables",
"LDA w/LASSO-Selected Variables", "QDA", "QDA w/RF-Selected Variables",
"QDA w/LASSO-Selected Variables", "LASSO Logistic Regression")
results %>%
kbl(caption = "Prediction Results for Individual Methods") %>%
kable_classic(full_width = FALSE, html_font = "Cambria",
latex_options = "HOLD_position")
library(tidyverse)
library(dplyr)
library(MASS)
library(verification)
library(caTools)
library(klaR)
library(randomForest)
library(glmnet)
library(ggplot2)
library(knitr)
library(gridExtra)
library(kableExtra)
results <- data.frame(PCC = c(76.99, 75.23, 77.09, 73.15, 71.40, 72.16, 77.10),
Specificity = c(79.91, 79.07, 80.01, 88.25, 89.99, 89.76,
79.53))
rownames(results) <- c("LDA", "LDA w/RF-Selected Variables",
"LDA w/LASSO-Selected Variables", "QDA", "QDA w/RF-Selected Variables",
"QDA w/LASSO-Selected Variables", "LASSO Logistic Regression")
results %>%
kbl(caption = "Prediction Results for Individual Methods") %>%
kable_classic(full_width = FALSE, html_font = "Cambria",
latex_options = "HOLD_position")
class.sum(train_sample$HeartDiseaseorAttack, predict(rf, type="prob")[,2], cap = "Training Data RF Performance")
class.sum(test_sample$HeartDiseaseorAttack, predict(rf, test_sample, type="prob")[,2], cap = "Test Data RF Performance")
results <- data.frame(PCC = c(76.99, 75.23, 77.09, 73.15, 71.40, 72.16, 77.10,74.73),
Specificity = c(79.91, 79.07, 80.01, 88.25, 89.99, 89.76,
79.53, 69.69))
rownames(results) <- c("LDA", "LDA w/RF-Selected Variables",
"LDA w/LASSO-Selected Variables", "QDA", "QDA w/RF-Selected Variables",
"QDA w/LASSO-Selected Variables", "LASSO Logistic Regression", "Random Forest w/ RF-Selected Variables")
results.table <- results %>%
kbl(caption = "Prediction Results for Individual Methods") %>%
kable_classic(full_width = FALSE, html_font = "Cambria",
latex_options = "HOLD_position")
results.table
# Random Forest with LASSO selected variables
train_sample.lasso <- sample_n(lasso_test_features, 10000)
health <- read.csv("heart_disease_health_indicators.csv")
health <- health %>% mutate(
HeartDiseaseorAttack = HeartDiseaseorAttack,
HighBP = as.factor(HighBP),  # LASSO approved
HighChol = as.factor(HighChol),  # LASSO approved
CholCheck = as.factor(CholCheck),
ln.BMI = log(BMI),  # RF approved
Smoker = as.factor(Smoker),  # LASSO approved
Stroke = as.factor(Stroke),  # LASSO 1-SE only, RF approved
Diabetes = as.factor(Diabetes),  # LASSO approved, RF approved
PhysActivity = as.factor(PhysActivity),
Fruits = as.factor(Fruits),
Veggies = as.factor(Veggies),
HvyAlcoholConsump = as.factor(HvyAlcoholConsump),
AnyHealthcare = as.factor(AnyHealthcare),
NoDocbcCost = as.factor(NoDocbcCost),  # LASSO approved
GenHlth = as.factor(GenHlth),  # LASSO approved, RF approved
ln.MentHlth = log(MentHlth + 1), # Probably shouldn't use
bin.MentHlth = as.factor(ifelse(MentHlth == 0, 0, 1)),  #RF approved
fac.MentHlth = as.factor(MentHlth), # Probably shouldn't use
ln.PhysHlth = log(PhysHlth + 1), # Probably shouldn't use
bin.PhysHlth = as.factor(ifelse(PhysHlth == 0, 0, 1)),  # LASSO approved, RF approved
fac.PhysHlth = as.factor(PhysHlth), # Probably shouldn't use
DiffWalk = as.factor(DiffWalk),  # LASSO , RF approved
Sex = as.factor(ifelse(Sex == 0, "F", "M")),  # LASSO approved, RF approved
Age = as.factor(Age),  # LASSO approved, RF approved
Education = as.factor(Education),  # RF approved
Income = as.factor(Income)  # LASSO approved, RF approved
)
# new data with transformed variables
health_subset <- health[c(1:4, 6:15, 18:23, 25, 28)]
# Train and Test Sets
health_tmp <- sample.split(health_subset, SplitRatio = 0.3)
test <- subset(health_subset, health_tmp == TRUE)
train <- subset(health_subset, health_tmp == FALSE)
## Randomly sample rows
train_sample <- sample_n(train, 5000)
## UpSample to deal with class imbalance
new_train <- upSample(train[,2:22], as.factor(train[,1]), list=FALSE) %>%
mutate(HeartDiseaseorAttack = as.numeric(Class)-1)
library(caret)
## UpSample to deal with class imbalance
new_train <- upSample(train[,2:22], as.factor(train[,1]), list=FALSE) %>%
mutate(HeartDiseaseorAttack = as.numeric(Class)-1)
## Test Set Upsample ##
new_test <- upSample(test[,2:22], as.factor(test[,1]), list = FALSE) %>%
mutate(HeartDiseaseorAttack = as.numeric(Class)-1)
lasso_best_features <- new_train %>% dplyr::select(HeartDiseaseorAttack, HighBP,
HighChol, CholCheck, Smoker,
Stroke, Diabetes, HvyAlcoholConsump,
NoDocbcCost, GenHlth, DiffWalk,
Sex, Age, Income, bin.PhysHlth)
lasso_test_features <- new_test %>% dplyr::select(HeartDiseaseorAttack, HighBP,
HighChol, CholCheck, Smoker,
Stroke, Diabetes, HvyAlcoholConsump,
NoDocbcCost, GenHlth, DiffWalk,
Sex, Age, Income, bin.PhysHlth)
# Random Forest with LASSO selected variables
train_sample.lasso <- sample_n(lasso_test_features, 10000)
test_sample.lasso <- sample_n(lasso_test_features, 10000)
rf.lasso <- randomForest(as.factor(HeartDiseaseorAttack) ~ ., data = train_sample.lasso, n.trees = 100)
class.sum(train_sample.lasso$HeartDiseaseorAttack, predict(rf.lasso, type="prob")[,2], cap = "Training Data RF Performance")
class.sum(test_sample.lasso$HeartDiseaseorAttack, predict(rf.lasso, test_sample.lasso, type="prob")[,2], cap = "Test Data RF Performance")
results <- data.frame(PCC = c(76.99, 75.23, 77.09, 73.15, 71.40, 72.16, 77.10,74.73,79.11),
Specificity = c(79.91, 79.07, 80.01, 88.25, 89.99, 89.76,
79.53, 69.69,74.45))
rownames(results) <- c("LDA", "LDA w/RF-Selected Variables",
"LDA w/LASSO-Selected Variables", "QDA", "QDA w/RF-Selected Variables",
"QDA w/LASSO-Selected Variables", "LASSO Logistic Regression", "RF w/ RF-Selected Variables", "RF w/ LASSO-Selected Variables")
results.table <- results %>%
kbl(caption = "Prediction Results for Individual Methods") %>%
kable_classic(full_width = FALSE, html_font = "Cambria",
latex_options = "HOLD_position")
results.table
pnorm(350,400,sqrt(1200))
pnorm(350,250,sqrt(375),lower.tail = FALSE)
